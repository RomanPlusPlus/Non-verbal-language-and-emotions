# Non-verbal language project
    Project for develop a set of models and scripts inside of framework 
    oriented to human emotions recognition in a whole system or specific parts.

## Acknowledgement
Acknowledgement for the people who provided pictures and feedback for improvements in this project:
* EDLRL
* Sideloading group
* Roman Sitelew

## Description
This project consists of three well-defined objectives:

1. To create a model to recognise basic and acquired human emotions.

2. To create a model to recognise human emotions by tone.

3. To create a model to recognise body language.
4. To create a model to recognise hand gesture.

The datasets will be generated by means of Google's project 'The Techeable Machine' and exported to various existing formats. 
It is open source and collaboration is expected from various people to extend this dataset to generate a deep non-verbal recognition capability in a programme.

It has to be kept in mind that the extension of the dataset has to be organised and discussed directly among all participants, thus reducing cognitive bias in the dataset. 

## Installation
- virtualenv env --python=python==3.10.6
- $ pip install -r requirements.txt

## Execution
- python whole_body_record_data_video.py

## testing on:
- Python 3.10.6
- Ubuntu 22.04.2 LTS
- HP Laptop 15s-eq1xxx
- AMD® Ryzen 7 4700u with radeon graphics × 8

### Sources and references:

* [The Techeable Machine](https://teachablemachine.withgoogle.com/)
    
* [Paul Ekman](https://www.paulekman.com/)
    
* [Vanessa Van Edwars](https://en.wikipedia.org/wiki/Vanessa_Van_Edwards)
    
* [Allan Pease](https://en.wikipedia.org/wiki/Allan_Pease)
    
* [non verbal language](https://en.wikipedia.org/wiki/Body_language)

